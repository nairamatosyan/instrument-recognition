{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98aa9328",
   "metadata": {
    "id": "98aa9328",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1707637431483,
     "user_tz": -240,
     "elapsed": 6056,
     "user": {
      "displayName": "Naira Matosyan",
      "userId": "06300012502933898371"
     }
    }
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "\n",
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b92c614c",
   "metadata": {
    "id": "b92c614c",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1707637436491,
     "user_tz": -240,
     "elapsed": 768,
     "user": {
      "displayName": "Naira Matosyan",
      "userId": "06300012502933898371"
     }
    }
   },
   "outputs": [],
   "source": [
    "torch._C._cuda_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed01e7e8",
   "metadata": {
    "id": "ed01e7e8",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1707637438871,
     "user_tz": -240,
     "elapsed": 3,
     "user": {
      "displayName": "Naira Matosyan",
      "userId": "06300012502933898371"
     }
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6c0eaad",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d6c0eaad",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1707637468755,
     "user_tz": -240,
     "elapsed": 26918,
     "user": {
      "displayName": "Naira Matosyan",
      "userId": "06300012502933898371"
     }
    },
    "outputId": "d04df030-4b97-4351-958b-26560391bce0"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f547a22f",
   "metadata": {
    "id": "f547a22f",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1707637476442,
     "user_tz": -240,
     "elapsed": 415,
     "user": {
      "displayName": "Naira Matosyan",
      "userId": "06300012502933898371"
     }
    }
   },
   "outputs": [],
   "source": [
    "def feature_extract(file):\n",
    "    #get wave representation\n",
    "    y, sr = librosa.load(file)\n",
    "\n",
    "    #get the mel-scaled spectrogram\n",
    "    spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128,fmax=11025)\n",
    "\n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07c54cf1",
   "metadata": {
    "id": "07c54cf1",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1707617209373,
     "user_tz": -240,
     "elapsed": 3,
     "user": {
      "displayName": "Naira Matosyan",
      "userId": "06300012502933898371"
     }
    }
   },
   "outputs": [],
   "source": [
    "def plot_spectogram(sp, sr, label):\n",
    "    S_DB = librosa.amplitude_to_db(sp, ref=np.max)\n",
    "\n",
    "    # Plot the Mel-spectrogram\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(S_DB, sr=sr, x_axis='time', y_axis='mel')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title(f'Mel-Spectrogram of {label}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "966fb5c6",
   "metadata": {
    "id": "966fb5c6",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1707637480930,
     "user_tz": -240,
     "elapsed": 1,
     "user": {
      "displayName": "Naira Matosyan",
      "userId": "06300012502933898371"
     }
    }
   },
   "outputs": [],
   "source": [
    "class InstrumentDataset(Dataset):\n",
    "    def __init__(self, audio_dir, transformation):\n",
    "        self.audio_labels = []\n",
    "        self.audio_paths = []\n",
    "        self.audio_dir = audio_dir\n",
    "        self.classes = {'cel': 0, 'cla': 1, 'flu': 2, 'gac': 3, 'gel': 4, 'org': 5, 'pia': 6, 'sax': 7, 'tru': 8, 'vio': 9, 'voi': 10}\n",
    "        self.transformation = transformation\n",
    "\n",
    "        # Scan the directory and get audio paths and labels\n",
    "        for label in os.listdir(audio_dir):\n",
    "            label_dir = os.path.join(audio_dir, label)\n",
    "            if os.path.isdir(label_dir):\n",
    "                for file in os.listdir(label_dir):\n",
    "                    if file.endswith('.wav'):\n",
    "                        self.audio_paths.append(os.path.join(label_dir, file))\n",
    "                        self.audio_labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audio_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        audio_path = self.audio_paths[index]\n",
    "        label = self.audio_labels[index]\n",
    "        return self.transformation(audio_path), self.classes[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3ae081e",
   "metadata": {
    "id": "c3ae081e",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1707637496289,
     "user_tz": -240,
     "elapsed": 11673,
     "user": {
      "displayName": "Naira Matosyan",
      "userId": "06300012502933898371"
     }
    }
   },
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "\n",
    "dataset = InstrumentDataset(audio_dir='drive/MyDrive/audio_data', transformation=feature_extract)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = InstrumentDataset(audio_dir='drive/MyDrive/audio_test_data', transformation=feature_extract)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "77429df7",
   "metadata": {
    "id": "77429df7",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1707639433424,
     "user_tz": -240,
     "elapsed": 2378,
     "user": {
      "displayName": "Naira Matosyan",
      "userId": "06300012502933898371"
     }
    }
   },
   "outputs": [],
   "source": [
    "class InstrumentCNN(nn.Module):\n",
    "    def __init__(self, output_shape: int):\n",
    "        super().__init__()\n",
    "        self.block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1,\n",
    "                      out_channels=16,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1\n",
    "                      ),\n",
    "            nn.BatchNorm2d(num_features=16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=16,\n",
    "                      out_channels=32,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1\n",
    "                      ),\n",
    "            nn.BatchNorm2d(num_features=32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=32,\n",
    "                      out_channels=64,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1\n",
    "                      ),\n",
    "            nn.BatchNorm2d(num_features=64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=16384, out_features=512),\n",
    "            nn.BatchNorm1d(num_features=512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=512, out_features=output_shape)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block_1(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c60e63b5",
   "metadata": {
    "id": "c60e63b5",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1707639440194,
     "user_tz": -240,
     "elapsed": 4,
     "user": {
      "displayName": "Naira Matosyan",
      "userId": "06300012502933898371"
     }
    }
   },
   "outputs": [],
   "source": [
    "class InstrumentLSTM(nn.Module):\n",
    "    def __init__(self, output_shape: int):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=128, hidden_size=256, num_layers=2, batch_first=True)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, output_shape)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape is expected to be [batch, seq_len, features] where features is input_size\n",
    "        lstm_out, (hn, cn) = self.lstm(x)\n",
    "        # Taking the last hidden state to pass through the classifier\n",
    "        x = hn[-1]  # Shape: [batch, hidden_size]\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "01439bb9",
   "metadata": {
    "id": "01439bb9",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1707639446111,
     "user_tz": -240,
     "elapsed": 2,
     "user": {
      "displayName": "Naira Matosyan",
      "userId": "06300012502933898371"
     }
    }
   },
   "outputs": [],
   "source": [
    "num_classes = 11  # Set the number of classes\n",
    "epochs = 30\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362ac15f",
   "metadata": {
    "id": "362ac15f"
   },
   "outputs": [],
   "source": [
    "model = InstrumentCNN(num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch}\\n-------\")\n",
    "    ### Training\n",
    "    train_loss = 0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        X = X.unsqueeze(1)\n",
    "        model.train()\n",
    "        y_pred = model(X).to(device)\n",
    "        loss = criterion(y_pred, y)\n",
    "        loss = loss.to(device)\n",
    "        train_loss += loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch % 10 == 0:\n",
    "            print(f\"Looked at {batch * len(X)}/{len(dataloader.dataset)} samples\")\n",
    "\n",
    "    train_loss /= len(dataloader)\n",
    "    model.eval()\n",
    "    torch.save(model.state_dict(), 'checkpoints_lstm/epoch_{}.pth'.format(epoch))\n",
    "    print(f\"\\nTrain loss: {train_loss:.5f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "77f2c10e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "a8926c2f3a114d14b668bbe75e90c39b",
      "a2358816bb7a4cf6ac325ea2afc66f53",
      "c319a55f2c86488fa527d0afec77abb3",
      "48645e504a8e4d238809feca3f4eea46",
      "27b278f7ba124188a95967c48687ae51",
      "9af1f6bc7bef46c68da8f5faac96c89c",
      "665621f698ca40e7b12add05a3695c88",
      "e73dc229b0c041ccb9c2a0c2a0cddd1c",
      "fdee0def9dc44d9d9b0e5ab2b133c1b4",
      "efb35c962e6541608d2362f068b06c67",
      "d4b3a2a5f7a14af2999b9c9e32aab348"
     ]
    },
    "id": "77f2c10e",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1707627549933,
     "user_tz": -240,
     "elapsed": 6714373,
     "user": {
      "displayName": "Naira Matosyan",
      "userId": "06300012502933898371"
     }
    },
    "outputId": "f0f97b3b-c04f-4b3d-8ff0-487b22db5afa"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a8926c2f3a114d14b668bbe75e90c39b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 0\n",
      "-------\n",
      "Looked at 0/6705 samples\n",
      "Looked at 320/6705 samples\n",
      "Looked at 640/6705 samples\n",
      "Looked at 960/6705 samples\n",
      "Looked at 1280/6705 samples\n",
      "Looked at 1600/6705 samples\n",
      "Looked at 1920/6705 samples\n",
      "Looked at 2240/6705 samples\n",
      "Looked at 2560/6705 samples\n",
      "Looked at 2880/6705 samples\n",
      "Looked at 3200/6705 samples\n",
      "Looked at 3520/6705 samples\n",
      "Looked at 3840/6705 samples\n",
      "Looked at 4160/6705 samples\n",
      "Looked at 4480/6705 samples\n",
      "Looked at 4800/6705 samples\n",
      "Looked at 5120/6705 samples\n",
      "Looked at 5440/6705 samples\n",
      "Looked at 5760/6705 samples\n",
      "Looked at 6080/6705 samples\n",
      "Looked at 6400/6705 samples\n",
      "\n",
      "Train loss: 2.20651%\n",
      "\n",
      "Epoch: 1\n",
      "-------\n",
      "Looked at 0/6705 samples\n",
      "Looked at 320/6705 samples\n",
      "Looked at 640/6705 samples\n",
      "Looked at 960/6705 samples\n",
      "Looked at 1280/6705 samples\n",
      "Looked at 1600/6705 samples\n",
      "Looked at 1920/6705 samples\n",
      "Looked at 2240/6705 samples\n",
      "Looked at 2560/6705 samples\n",
      "Looked at 2880/6705 samples\n",
      "Looked at 3200/6705 samples\n",
      "Looked at 3520/6705 samples\n",
      "Looked at 3840/6705 samples\n",
      "Looked at 4160/6705 samples\n",
      "Looked at 4480/6705 samples\n",
      "Looked at 4800/6705 samples\n",
      "Looked at 5120/6705 samples\n",
      "Looked at 5440/6705 samples\n",
      "Looked at 5760/6705 samples\n",
      "Looked at 6080/6705 samples\n",
      "Looked at 6400/6705 samples\n",
      "\n",
      "Train loss: 1.97059%\n",
      "\n",
      "Epoch: 2\n",
      "-------\n",
      "Looked at 0/6705 samples\n",
      "Looked at 320/6705 samples\n",
      "Looked at 640/6705 samples\n",
      "Looked at 960/6705 samples\n",
      "Looked at 1280/6705 samples\n",
      "Looked at 1600/6705 samples\n",
      "Looked at 1920/6705 samples\n",
      "Looked at 2240/6705 samples\n",
      "Looked at 2560/6705 samples\n",
      "Looked at 2880/6705 samples\n",
      "Looked at 3200/6705 samples\n",
      "Looked at 3520/6705 samples\n",
      "Looked at 3840/6705 samples\n",
      "Looked at 4160/6705 samples\n",
      "Looked at 4480/6705 samples\n",
      "Looked at 4800/6705 samples\n",
      "Looked at 5120/6705 samples\n",
      "Looked at 5440/6705 samples\n",
      "Looked at 5760/6705 samples\n",
      "Looked at 6080/6705 samples\n",
      "Looked at 6400/6705 samples\n",
      "\n",
      "Train loss: 1.80670%\n",
      "\n",
      "Epoch: 3\n",
      "-------\n",
      "Looked at 0/6705 samples\n",
      "Looked at 320/6705 samples\n",
      "Looked at 640/6705 samples\n",
      "Looked at 960/6705 samples\n",
      "Looked at 1280/6705 samples\n",
      "Looked at 1600/6705 samples\n",
      "Looked at 1920/6705 samples\n",
      "Looked at 2240/6705 samples\n",
      "Looked at 2560/6705 samples\n",
      "Looked at 2880/6705 samples\n",
      "Looked at 3200/6705 samples\n",
      "Looked at 3520/6705 samples\n",
      "Looked at 3840/6705 samples\n",
      "Looked at 4160/6705 samples\n",
      "Looked at 4480/6705 samples\n",
      "Looked at 4800/6705 samples\n",
      "Looked at 5120/6705 samples\n",
      "Looked at 5440/6705 samples\n",
      "Looked at 5760/6705 samples\n",
      "Looked at 6080/6705 samples\n",
      "Looked at 6400/6705 samples\n",
      "\n",
      "Train loss: 1.65107%\n",
      "\n",
      "Epoch: 4\n",
      "-------\n",
      "Looked at 0/6705 samples\n",
      "Looked at 320/6705 samples\n",
      "Looked at 640/6705 samples\n",
      "Looked at 960/6705 samples\n",
      "Looked at 1280/6705 samples\n",
      "Looked at 1600/6705 samples\n",
      "Looked at 1920/6705 samples\n",
      "Looked at 2240/6705 samples\n",
      "Looked at 2560/6705 samples\n",
      "Looked at 2880/6705 samples\n",
      "Looked at 3200/6705 samples\n",
      "Looked at 3520/6705 samples\n",
      "Looked at 3840/6705 samples\n",
      "Looked at 4160/6705 samples\n",
      "Looked at 4480/6705 samples\n",
      "Looked at 4800/6705 samples\n",
      "Looked at 5120/6705 samples\n",
      "Looked at 5440/6705 samples\n",
      "Looked at 5760/6705 samples\n",
      "Looked at 6080/6705 samples\n",
      "Looked at 6400/6705 samples\n",
      "\n",
      "Train loss: 1.50897%\n",
      "\n",
      "Epoch: 5\n",
      "-------\n",
      "Looked at 0/6705 samples\n",
      "Looked at 320/6705 samples\n",
      "Looked at 640/6705 samples\n",
      "Looked at 960/6705 samples\n",
      "Looked at 1280/6705 samples\n",
      "Looked at 1600/6705 samples\n",
      "Looked at 1920/6705 samples\n",
      "Looked at 2240/6705 samples\n",
      "Looked at 2560/6705 samples\n",
      "Looked at 2880/6705 samples\n",
      "Looked at 3200/6705 samples\n",
      "Looked at 3520/6705 samples\n",
      "Looked at 3840/6705 samples\n",
      "Looked at 4160/6705 samples\n",
      "Looked at 4480/6705 samples\n",
      "Looked at 4800/6705 samples\n",
      "Looked at 5120/6705 samples\n",
      "Looked at 5440/6705 samples\n",
      "Looked at 5760/6705 samples\n",
      "Looked at 6080/6705 samples\n",
      "Looked at 6400/6705 samples\n",
      "\n",
      "Train loss: 1.37715%\n",
      "\n",
      "Epoch: 6\n",
      "-------\n",
      "Looked at 0/6705 samples\n",
      "Looked at 320/6705 samples\n",
      "Looked at 640/6705 samples\n",
      "Looked at 960/6705 samples\n",
      "Looked at 1280/6705 samples\n",
      "Looked at 1600/6705 samples\n",
      "Looked at 1920/6705 samples\n",
      "Looked at 2240/6705 samples\n",
      "Looked at 2560/6705 samples\n",
      "Looked at 2880/6705 samples\n",
      "Looked at 3200/6705 samples\n",
      "Looked at 3520/6705 samples\n",
      "Looked at 3840/6705 samples\n",
      "Looked at 4160/6705 samples\n",
      "Looked at 4480/6705 samples\n",
      "Looked at 4800/6705 samples\n",
      "Looked at 5120/6705 samples\n",
      "Looked at 5440/6705 samples\n",
      "Looked at 5760/6705 samples\n",
      "Looked at 6080/6705 samples\n",
      "Looked at 6400/6705 samples\n",
      "\n",
      "Train loss: 1.25530%\n",
      "\n",
      "Epoch: 7\n",
      "-------\n",
      "Looked at 0/6705 samples\n",
      "Looked at 320/6705 samples\n",
      "Looked at 640/6705 samples\n",
      "Looked at 960/6705 samples\n",
      "Looked at 1280/6705 samples\n",
      "Looked at 1600/6705 samples\n",
      "Looked at 1920/6705 samples\n",
      "Looked at 2240/6705 samples\n",
      "Looked at 2560/6705 samples\n",
      "Looked at 2880/6705 samples\n",
      "Looked at 3200/6705 samples\n",
      "Looked at 3520/6705 samples\n",
      "Looked at 3840/6705 samples\n",
      "Looked at 4160/6705 samples\n",
      "Looked at 4480/6705 samples\n",
      "Looked at 4800/6705 samples\n",
      "Looked at 5120/6705 samples\n",
      "Looked at 5440/6705 samples\n",
      "Looked at 5760/6705 samples\n",
      "Looked at 6080/6705 samples\n",
      "Looked at 6400/6705 samples\n",
      "\n",
      "Train loss: 1.12814%\n",
      "\n",
      "Epoch: 8\n",
      "-------\n",
      "Looked at 0/6705 samples\n",
      "Looked at 320/6705 samples\n",
      "Looked at 640/6705 samples\n",
      "Looked at 960/6705 samples\n",
      "Looked at 1280/6705 samples\n",
      "Looked at 1600/6705 samples\n",
      "Looked at 1920/6705 samples\n",
      "Looked at 2240/6705 samples\n",
      "Looked at 2560/6705 samples\n",
      "Looked at 2880/6705 samples\n",
      "Looked at 3200/6705 samples\n",
      "Looked at 3520/6705 samples\n",
      "Looked at 3840/6705 samples\n",
      "Looked at 4160/6705 samples\n",
      "Looked at 4480/6705 samples\n",
      "Looked at 4800/6705 samples\n",
      "Looked at 5120/6705 samples\n",
      "Looked at 5440/6705 samples\n",
      "Looked at 5760/6705 samples\n",
      "Looked at 6080/6705 samples\n",
      "Looked at 6400/6705 samples\n",
      "\n",
      "Train loss: 0.97384%\n",
      "\n",
      "Epoch: 9\n",
      "-------\n",
      "Looked at 0/6705 samples\n",
      "Looked at 320/6705 samples\n",
      "Looked at 640/6705 samples\n",
      "Looked at 960/6705 samples\n",
      "Looked at 1280/6705 samples\n",
      "Looked at 1600/6705 samples\n",
      "Looked at 1920/6705 samples\n",
      "Looked at 2240/6705 samples\n",
      "Looked at 2560/6705 samples\n",
      "Looked at 2880/6705 samples\n",
      "Looked at 3200/6705 samples\n",
      "Looked at 3520/6705 samples\n",
      "Looked at 3840/6705 samples\n",
      "Looked at 4160/6705 samples\n",
      "Looked at 4480/6705 samples\n",
      "Looked at 4800/6705 samples\n",
      "Looked at 5120/6705 samples\n",
      "Looked at 5440/6705 samples\n",
      "Looked at 5760/6705 samples\n",
      "Looked at 6080/6705 samples\n",
      "Looked at 6400/6705 samples\n",
      "\n",
      "Train loss: 0.84965%\n",
      "\n",
      "Epoch: 10\n",
      "-------\n",
      "Looked at 0/6705 samples\n",
      "Looked at 320/6705 samples\n",
      "Looked at 640/6705 samples\n",
      "Looked at 960/6705 samples\n",
      "Looked at 1280/6705 samples\n",
      "Looked at 1600/6705 samples\n",
      "Looked at 1920/6705 samples\n",
      "Looked at 2240/6705 samples\n",
      "Looked at 2560/6705 samples\n",
      "Looked at 2880/6705 samples\n",
      "Looked at 3200/6705 samples\n",
      "Looked at 3520/6705 samples\n",
      "Looked at 3840/6705 samples\n",
      "Looked at 4160/6705 samples\n",
      "Looked at 4480/6705 samples\n",
      "Looked at 4800/6705 samples\n",
      "Looked at 5120/6705 samples\n",
      "Looked at 5440/6705 samples\n",
      "Looked at 5760/6705 samples\n",
      "Looked at 6080/6705 samples\n",
      "Looked at 6400/6705 samples\n",
      "\n",
      "Train loss: 0.78052%\n",
      "\n",
      "Epoch: 11\n",
      "-------\n",
      "Looked at 0/6705 samples\n",
      "Looked at 320/6705 samples\n",
      "Looked at 640/6705 samples\n",
      "Looked at 960/6705 samples\n",
      "Looked at 1280/6705 samples\n",
      "Looked at 1600/6705 samples\n",
      "Looked at 1920/6705 samples\n",
      "Looked at 2240/6705 samples\n",
      "Looked at 2560/6705 samples\n",
      "Looked at 2880/6705 samples\n",
      "Looked at 3200/6705 samples\n",
      "Looked at 3520/6705 samples\n",
      "Looked at 3840/6705 samples\n",
      "Looked at 4160/6705 samples\n",
      "Looked at 4480/6705 samples\n",
      "Looked at 4800/6705 samples\n",
      "Looked at 5120/6705 samples\n",
      "Looked at 5440/6705 samples\n",
      "Looked at 5760/6705 samples\n",
      "Looked at 6080/6705 samples\n",
      "Looked at 6400/6705 samples\n",
      "\n",
      "Train loss: 0.67158%\n",
      "\n",
      "Epoch: 12\n",
      "-------\n",
      "Looked at 0/6705 samples\n",
      "Looked at 320/6705 samples\n",
      "Looked at 640/6705 samples\n",
      "Looked at 960/6705 samples\n",
      "Looked at 1280/6705 samples\n",
      "Looked at 1600/6705 samples\n",
      "Looked at 1920/6705 samples\n",
      "Looked at 2240/6705 samples\n",
      "Looked at 2560/6705 samples\n",
      "Looked at 2880/6705 samples\n",
      "Looked at 3200/6705 samples\n",
      "Looked at 3520/6705 samples\n",
      "Looked at 3840/6705 samples\n",
      "Looked at 4160/6705 samples\n",
      "Looked at 4480/6705 samples\n",
      "Looked at 4800/6705 samples\n",
      "Looked at 5120/6705 samples\n",
      "Looked at 5440/6705 samples\n",
      "Looked at 5760/6705 samples\n",
      "Looked at 6080/6705 samples\n",
      "Looked at 6400/6705 samples\n",
      "\n",
      "Train loss: 0.58687%\n",
      "\n",
      "Epoch: 13\n",
      "-------\n",
      "Looked at 0/6705 samples\n",
      "Looked at 320/6705 samples\n",
      "Looked at 640/6705 samples\n",
      "Looked at 960/6705 samples\n",
      "Looked at 1280/6705 samples\n",
      "Looked at 1600/6705 samples\n",
      "Looked at 1920/6705 samples\n",
      "Looked at 2240/6705 samples\n",
      "Looked at 2560/6705 samples\n",
      "Looked at 2880/6705 samples\n",
      "Looked at 3200/6705 samples\n",
      "Looked at 3520/6705 samples\n",
      "Looked at 3840/6705 samples\n",
      "Looked at 4160/6705 samples\n",
      "Looked at 4480/6705 samples\n",
      "Looked at 4800/6705 samples\n",
      "Looked at 5120/6705 samples\n",
      "Looked at 5440/6705 samples\n",
      "Looked at 5760/6705 samples\n",
      "Looked at 6080/6705 samples\n",
      "Looked at 6400/6705 samples\n",
      "\n",
      "Train loss: 0.50059%\n",
      "\n",
      "Epoch: 14\n",
      "-------\n",
      "Looked at 0/6705 samples\n",
      "Looked at 320/6705 samples\n",
      "Looked at 640/6705 samples\n",
      "Looked at 960/6705 samples\n",
      "Looked at 1280/6705 samples\n",
      "Looked at 1600/6705 samples\n",
      "Looked at 1920/6705 samples\n",
      "Looked at 2240/6705 samples\n",
      "Looked at 2560/6705 samples\n",
      "Looked at 2880/6705 samples\n",
      "Looked at 3200/6705 samples\n",
      "Looked at 3520/6705 samples\n",
      "Looked at 3840/6705 samples\n",
      "Looked at 4160/6705 samples\n",
      "Looked at 4480/6705 samples\n",
      "Looked at 4800/6705 samples\n",
      "Looked at 5120/6705 samples\n",
      "Looked at 5440/6705 samples\n",
      "Looked at 5760/6705 samples\n",
      "Looked at 6080/6705 samples\n",
      "Looked at 6400/6705 samples\n",
      "\n",
      "Train loss: 0.43853%\n",
      "\n",
      "Epoch: 15\n",
      "-------\n",
      "Looked at 0/6705 samples\n",
      "Looked at 320/6705 samples\n",
      "Looked at 640/6705 samples\n",
      "Looked at 960/6705 samples\n",
      "Looked at 1280/6705 samples\n",
      "Looked at 1600/6705 samples\n",
      "Looked at 1920/6705 samples\n",
      "Looked at 2240/6705 samples\n",
      "Looked at 2560/6705 samples\n",
      "Looked at 2880/6705 samples\n",
      "Looked at 3200/6705 samples\n",
      "Looked at 3520/6705 samples\n",
      "Looked at 3840/6705 samples\n",
      "Looked at 4160/6705 samples\n",
      "Looked at 4480/6705 samples\n",
      "Looked at 4800/6705 samples\n",
      "Looked at 5120/6705 samples\n",
      "Looked at 5440/6705 samples\n",
      "Looked at 5760/6705 samples\n",
      "Looked at 6080/6705 samples\n",
      "Looked at 6400/6705 samples\n",
      "\n",
      "Train loss: 0.40717%\n",
      "\n",
      "Epoch: 16\n",
      "-------\n",
      "Looked at 0/6705 samples\n",
      "Looked at 320/6705 samples\n",
      "Looked at 640/6705 samples\n",
      "Looked at 960/6705 samples\n",
      "Looked at 1280/6705 samples\n",
      "Looked at 1600/6705 samples\n",
      "Looked at 1920/6705 samples\n",
      "Looked at 2240/6705 samples\n",
      "Looked at 2560/6705 samples\n",
      "Looked at 2880/6705 samples\n",
      "Looked at 3200/6705 samples\n",
      "Looked at 3520/6705 samples\n",
      "Looked at 3840/6705 samples\n",
      "Looked at 4160/6705 samples\n",
      "Looked at 4480/6705 samples\n",
      "Looked at 4800/6705 samples\n",
      "Looked at 5120/6705 samples\n",
      "Looked at 5440/6705 samples\n",
      "Looked at 5760/6705 samples\n",
      "Looked at 6080/6705 samples\n",
      "Looked at 6400/6705 samples\n",
      "\n",
      "Train loss: 0.42256%\n",
      "\n",
      "Epoch: 17\n",
      "-------\n",
      "Looked at 0/6705 samples\n",
      "Looked at 320/6705 samples\n",
      "Looked at 640/6705 samples\n",
      "Looked at 960/6705 samples\n",
      "Looked at 1280/6705 samples\n",
      "Looked at 1600/6705 samples\n",
      "Looked at 1920/6705 samples\n",
      "Looked at 2240/6705 samples\n",
      "Looked at 2560/6705 samples\n",
      "Looked at 2880/6705 samples\n",
      "Looked at 3200/6705 samples\n",
      "Looked at 3520/6705 samples\n",
      "Looked at 3840/6705 samples\n",
      "Looked at 4160/6705 samples\n",
      "Looked at 4480/6705 samples\n",
      "Looked at 4800/6705 samples\n",
      "Looked at 5120/6705 samples\n",
      "Looked at 5440/6705 samples\n",
      "Looked at 5760/6705 samples\n",
      "Looked at 6080/6705 samples\n",
      "Looked at 6400/6705 samples\n",
      "\n",
      "Train loss: 0.38938%\n",
      "\n",
      "Epoch: 18\n",
      "-------\n",
      "Looked at 0/6705 samples\n",
      "Looked at 320/6705 samples\n",
      "Looked at 640/6705 samples\n",
      "Looked at 960/6705 samples\n",
      "Looked at 1280/6705 samples\n",
      "Looked at 1600/6705 samples\n",
      "Looked at 1920/6705 samples\n",
      "Looked at 2240/6705 samples\n",
      "Looked at 2560/6705 samples\n",
      "Looked at 2880/6705 samples\n",
      "Looked at 3200/6705 samples\n",
      "Looked at 3520/6705 samples\n",
      "Looked at 3840/6705 samples\n",
      "Looked at 4160/6705 samples\n",
      "Looked at 4480/6705 samples\n",
      "Looked at 4800/6705 samples\n",
      "Looked at 5120/6705 samples\n",
      "Looked at 5440/6705 samples\n",
      "Looked at 5760/6705 samples\n",
      "Looked at 6080/6705 samples\n",
      "Looked at 6400/6705 samples\n",
      "\n",
      "Train loss: 0.40216%\n",
      "\n",
      "Epoch: 19\n",
      "-------\n",
      "Looked at 0/6705 samples\n",
      "Looked at 320/6705 samples\n",
      "Looked at 640/6705 samples\n",
      "Looked at 960/6705 samples\n",
      "Looked at 1280/6705 samples\n",
      "Looked at 1600/6705 samples\n",
      "Looked at 1920/6705 samples\n",
      "Looked at 2240/6705 samples\n",
      "Looked at 2560/6705 samples\n",
      "Looked at 2880/6705 samples\n",
      "Looked at 3200/6705 samples\n",
      "Looked at 3520/6705 samples\n",
      "Looked at 3840/6705 samples\n",
      "Looked at 4160/6705 samples\n",
      "Looked at 4480/6705 samples\n",
      "Looked at 4800/6705 samples\n",
      "Looked at 5120/6705 samples\n",
      "Looked at 5440/6705 samples\n",
      "Looked at 5760/6705 samples\n",
      "Looked at 6080/6705 samples\n",
      "Looked at 6400/6705 samples\n",
      "\n",
      "Train loss: 0.31686%\n",
      "\n",
      "Epoch: 20\n",
      "-------\n",
      "Looked at 0/6705 samples\n",
      "Looked at 320/6705 samples\n",
      "Looked at 640/6705 samples\n",
      "Looked at 960/6705 samples\n",
      "Looked at 1280/6705 samples\n",
      "Looked at 1600/6705 samples\n",
      "Looked at 1920/6705 samples\n",
      "Looked at 2240/6705 samples\n",
      "Looked at 2560/6705 samples\n",
      "Looked at 2880/6705 samples\n",
      "Looked at 3200/6705 samples\n",
      "Looked at 3520/6705 samples\n",
      "Looked at 3840/6705 samples\n",
      "Looked at 4160/6705 samples\n",
      "Looked at 4480/6705 samples\n",
      "Looked at 4800/6705 samples\n",
      "Looked at 5120/6705 samples\n",
      "Looked at 5440/6705 samples\n",
      "Looked at 5760/6705 samples\n",
      "Looked at 6080/6705 samples\n",
      "Looked at 6400/6705 samples\n",
      "\n",
      "Train loss: 0.28591%\n",
      "\n",
      "Epoch: 21\n",
      "-------\n",
      "Looked at 0/6705 samples\n",
      "Looked at 320/6705 samples\n",
      "Looked at 640/6705 samples\n",
      "Looked at 960/6705 samples\n",
      "Looked at 1280/6705 samples\n",
      "Looked at 1600/6705 samples\n",
      "Looked at 1920/6705 samples\n",
      "Looked at 2240/6705 samples\n",
      "Looked at 2560/6705 samples\n",
      "Looked at 2880/6705 samples\n",
      "Looked at 3200/6705 samples\n",
      "Looked at 3520/6705 samples\n",
      "Looked at 3840/6705 samples\n",
      "Looked at 4160/6705 samples\n",
      "Looked at 4480/6705 samples\n",
      "Looked at 4800/6705 samples\n",
      "Looked at 5120/6705 samples\n",
      "Looked at 5440/6705 samples\n",
      "Looked at 5760/6705 samples\n",
      "Looked at 6080/6705 samples\n",
      "Looked at 6400/6705 samples\n",
      "\n",
      "Train loss: 0.26664%\n",
      "\n",
      "Epoch: 22\n",
      "-------\n",
      "Looked at 0/6705 samples\n",
      "Looked at 320/6705 samples\n",
      "Looked at 640/6705 samples\n",
      "Looked at 960/6705 samples\n",
      "Looked at 1280/6705 samples\n",
      "Looked at 1600/6705 samples\n",
      "Looked at 1920/6705 samples\n",
      "Looked at 2240/6705 samples\n",
      "Looked at 2560/6705 samples\n",
      "Looked at 2880/6705 samples\n",
      "Looked at 3200/6705 samples\n",
      "Looked at 3520/6705 samples\n",
      "Looked at 3840/6705 samples\n",
      "Looked at 4160/6705 samples\n",
      "Looked at 4480/6705 samples\n",
      "Looked at 4800/6705 samples\n",
      "Looked at 5120/6705 samples\n",
      "Looked at 5440/6705 samples\n",
      "Looked at 5760/6705 samples\n",
      "Looked at 6080/6705 samples\n",
      "Looked at 6400/6705 samples\n",
      "\n",
      "Train loss: 0.24839%\n",
      "\n",
      "Epoch: 23\n",
      "-------\n",
      "Looked at 0/6705 samples\n",
      "Looked at 320/6705 samples\n",
      "Looked at 640/6705 samples\n",
      "Looked at 960/6705 samples\n",
      "Looked at 1280/6705 samples\n",
      "Looked at 1600/6705 samples\n",
      "Looked at 1920/6705 samples\n",
      "Looked at 2240/6705 samples\n",
      "Looked at 2560/6705 samples\n",
      "Looked at 2880/6705 samples\n",
      "Looked at 3200/6705 samples\n",
      "Looked at 3520/6705 samples\n",
      "Looked at 3840/6705 samples\n",
      "Looked at 4160/6705 samples\n",
      "Looked at 4480/6705 samples\n",
      "Looked at 4800/6705 samples\n",
      "Looked at 5120/6705 samples\n",
      "Looked at 5440/6705 samples\n",
      "Looked at 5760/6705 samples\n",
      "Looked at 6080/6705 samples\n",
      "Looked at 6400/6705 samples\n",
      "\n",
      "Train loss: 0.23492%\n",
      "\n",
      "Epoch: 24\n",
      "-------\n",
      "Looked at 0/6705 samples\n",
      "Looked at 320/6705 samples\n",
      "Looked at 640/6705 samples\n",
      "Looked at 960/6705 samples\n",
      "Looked at 1280/6705 samples\n",
      "Looked at 1600/6705 samples\n",
      "Looked at 1920/6705 samples\n",
      "Looked at 2240/6705 samples\n",
      "Looked at 2560/6705 samples\n",
      "Looked at 2880/6705 samples\n",
      "Looked at 3200/6705 samples\n",
      "Looked at 3520/6705 samples\n",
      "Looked at 3840/6705 samples\n",
      "Looked at 4160/6705 samples\n",
      "Looked at 4480/6705 samples\n",
      "Looked at 4800/6705 samples\n",
      "Looked at 5120/6705 samples\n",
      "Looked at 5440/6705 samples\n",
      "Looked at 5760/6705 samples\n",
      "Looked at 6080/6705 samples\n",
      "Looked at 6400/6705 samples\n",
      "\n",
      "Train loss: 0.27245%\n",
      "\n",
      "Epoch: 25\n",
      "-------\n",
      "Looked at 0/6705 samples\n",
      "Looked at 320/6705 samples\n",
      "Looked at 640/6705 samples\n",
      "Looked at 960/6705 samples\n",
      "Looked at 1280/6705 samples\n",
      "Looked at 1600/6705 samples\n",
      "Looked at 1920/6705 samples\n",
      "Looked at 2240/6705 samples\n",
      "Looked at 2560/6705 samples\n",
      "Looked at 2880/6705 samples\n",
      "Looked at 3200/6705 samples\n",
      "Looked at 3520/6705 samples\n",
      "Looked at 3840/6705 samples\n",
      "Looked at 4160/6705 samples\n",
      "Looked at 4480/6705 samples\n",
      "Looked at 4800/6705 samples\n",
      "Looked at 5120/6705 samples\n",
      "Looked at 5440/6705 samples\n",
      "Looked at 5760/6705 samples\n",
      "Looked at 6080/6705 samples\n",
      "Looked at 6400/6705 samples\n",
      "\n",
      "Train loss: 0.25503%\n",
      "\n",
      "Epoch: 26\n",
      "-------\n",
      "Looked at 0/6705 samples\n",
      "Looked at 320/6705 samples\n",
      "Looked at 640/6705 samples\n",
      "Looked at 960/6705 samples\n",
      "Looked at 1280/6705 samples\n",
      "Looked at 1600/6705 samples\n",
      "Looked at 1920/6705 samples\n",
      "Looked at 2240/6705 samples\n",
      "Looked at 2560/6705 samples\n",
      "Looked at 2880/6705 samples\n",
      "Looked at 3200/6705 samples\n",
      "Looked at 3520/6705 samples\n",
      "Looked at 3840/6705 samples\n",
      "Looked at 4160/6705 samples\n",
      "Looked at 4480/6705 samples\n",
      "Looked at 4800/6705 samples\n",
      "Looked at 5120/6705 samples\n",
      "Looked at 5440/6705 samples\n",
      "Looked at 5760/6705 samples\n",
      "Looked at 6080/6705 samples\n",
      "Looked at 6400/6705 samples\n",
      "\n",
      "Train loss: 0.25053%\n",
      "\n",
      "Epoch: 27\n",
      "-------\n",
      "Looked at 0/6705 samples\n",
      "Looked at 320/6705 samples\n",
      "Looked at 640/6705 samples\n",
      "Looked at 960/6705 samples\n",
      "Looked at 1280/6705 samples\n",
      "Looked at 1600/6705 samples\n",
      "Looked at 1920/6705 samples\n",
      "Looked at 2240/6705 samples\n",
      "Looked at 2560/6705 samples\n",
      "Looked at 2880/6705 samples\n",
      "Looked at 3200/6705 samples\n",
      "Looked at 3520/6705 samples\n",
      "Looked at 3840/6705 samples\n",
      "Looked at 4160/6705 samples\n",
      "Looked at 4480/6705 samples\n",
      "Looked at 4800/6705 samples\n",
      "Looked at 5120/6705 samples\n",
      "Looked at 5440/6705 samples\n",
      "Looked at 5760/6705 samples\n",
      "Looked at 6080/6705 samples\n",
      "Looked at 6400/6705 samples\n",
      "\n",
      "Train loss: 0.22367%\n",
      "\n",
      "Epoch: 28\n",
      "-------\n",
      "Looked at 0/6705 samples\n",
      "Looked at 320/6705 samples\n",
      "Looked at 640/6705 samples\n",
      "Looked at 960/6705 samples\n",
      "Looked at 1280/6705 samples\n",
      "Looked at 1600/6705 samples\n",
      "Looked at 1920/6705 samples\n",
      "Looked at 2240/6705 samples\n",
      "Looked at 2560/6705 samples\n",
      "Looked at 2880/6705 samples\n",
      "Looked at 3200/6705 samples\n",
      "Looked at 3520/6705 samples\n",
      "Looked at 3840/6705 samples\n",
      "Looked at 4160/6705 samples\n",
      "Looked at 4480/6705 samples\n",
      "Looked at 4800/6705 samples\n",
      "Looked at 5120/6705 samples\n",
      "Looked at 5440/6705 samples\n",
      "Looked at 5760/6705 samples\n",
      "Looked at 6080/6705 samples\n",
      "Looked at 6400/6705 samples\n",
      "\n",
      "Train loss: 0.18733%\n",
      "\n",
      "Epoch: 29\n",
      "-------\n",
      "Looked at 0/6705 samples\n",
      "Looked at 320/6705 samples\n",
      "Looked at 640/6705 samples\n",
      "Looked at 960/6705 samples\n",
      "Looked at 1280/6705 samples\n",
      "Looked at 1600/6705 samples\n",
      "Looked at 1920/6705 samples\n",
      "Looked at 2240/6705 samples\n",
      "Looked at 2560/6705 samples\n",
      "Looked at 2880/6705 samples\n",
      "Looked at 3200/6705 samples\n",
      "Looked at 3520/6705 samples\n",
      "Looked at 3840/6705 samples\n",
      "Looked at 4160/6705 samples\n",
      "Looked at 4480/6705 samples\n",
      "Looked at 4800/6705 samples\n",
      "Looked at 5120/6705 samples\n",
      "Looked at 5440/6705 samples\n",
      "Looked at 5760/6705 samples\n",
      "Looked at 6080/6705 samples\n",
      "Looked at 6400/6705 samples\n",
      "\n",
      "Train loss: 0.20769%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_lstm = InstrumentLSTM(num_classes).to(device)\n",
    "criterion_lstm = nn.CrossEntropyLoss()\n",
    "optimizer_lstm = optim.Adam(model_lstm.parameters(), lr=lr)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch}\\n-------\")\n",
    "    ### Training\n",
    "    train_loss = 0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        X = X.transpose(1, 2)\n",
    "        model_lstm.train()\n",
    "        y_pred = model_lstm(X).to(device)\n",
    "        loss = criterion_lstm(y_pred, y)\n",
    "        loss = loss.to(device)\n",
    "        train_loss += loss\n",
    "\n",
    "        optimizer_lstm.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer_lstm.step()\n",
    "        if batch % 10 == 0:\n",
    "            print(f\"Looked at {batch * len(X)}/{len(dataloader.dataset)} samples\")\n",
    "\n",
    "    train_loss /= len(dataloader)\n",
    "    model_lstm.eval()\n",
    "    torch.save(model_lstm.state_dict(), 'drive/MyDrive/checkpoints/lstm/epoch_{}.pth'.format(epoch))\n",
    "    print(f\"\\nTrain loss: {train_loss:.5f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "torch.save(model_lstm.state_dict(), 'drive/MyDrive/checkpoints/lstm/epoch_{}.pth'.format(0))"
   ],
   "metadata": {
    "id": "5eagL6byITXF",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1707620795019,
     "user_tz": -240,
     "elapsed": 3,
     "user": {
      "displayName": "Naira Matosyan",
      "userId": "06300012502933898371"
     }
    }
   },
   "id": "5eagL6byITXF",
   "execution_count": 35,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1a72a612",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1a72a612",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1707640346261,
     "user_tz": -240,
     "elapsed": 29126,
     "user": {
      "displayName": "Naira Matosyan",
      "userId": "06300012502933898371"
     }
    },
    "outputId": "5d8b7db5-13c4-4191-8d88-8a634ec03b20"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 0/42\n",
      "Batch: 1/42\n",
      "Batch: 2/42\n",
      "Batch: 3/42\n",
      "Batch: 4/42\n",
      "Batch: 5/42\n",
      "Batch: 6/42\n",
      "Batch: 7/42\n",
      "Batch: 8/42\n",
      "Batch: 9/42\n",
      "Batch: 10/42\n",
      "Batch: 11/42\n",
      "Batch: 12/42\n",
      "Batch: 13/42\n",
      "Batch: 14/42\n",
      "Batch: 15/42\n",
      "Batch: 16/42\n",
      "Batch: 17/42\n",
      "Batch: 18/42\n",
      "Batch: 19/42\n",
      "Batch: 20/42\n",
      "Batch: 21/42\n",
      "Batch: 22/42\n",
      "Batch: 23/42\n",
      "Batch: 24/42\n",
      "Batch: 25/42\n",
      "Batch: 26/42\n",
      "Batch: 27/42\n",
      "Batch: 28/42\n",
      "Batch: 29/42\n",
      "Batch: 30/42\n",
      "Batch: 31/42\n",
      "Batch: 32/42\n",
      "Batch: 33/42\n",
      "Batch: 34/42\n",
      "Batch: 35/42\n",
      "Batch: 36/42\n",
      "Batch: 37/42\n",
      "Batch: 38/42\n",
      "Batch: 39/42\n",
      "Batch: 40/42\n",
      "Batch: 41/42\n"
     ]
    }
   ],
   "source": [
    "# Evaluate CNN\n",
    "\n",
    "checkpoint = torch.load('drive/MyDrive/checkpoints/cnn/epoch_29.pth')\n",
    "loaded_model = InstrumentCNN(11)\n",
    "loaded_model.load_state_dict(checkpoint)\n",
    "loaded_model = loaded_model.to(device)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loaded_model.eval()\n",
    "y_true_cnn, y_pred_cnn = [], []\n",
    "with torch.no_grad():\n",
    "    for batch, (X, y) in enumerate(test_dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        X = X.unsqueeze(1)\n",
    "        output = loaded_model(X).to(device)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        y_true_cnn.extend(y)\n",
    "        y_pred_cnn.extend(predicted.cpu())\n",
    "        print(f\"Batch: {batch}/{len(test_dataloader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "619f8973",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "619f8973",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1707640283249,
     "user_tz": -240,
     "elapsed": 28071,
     "user": {
      "displayName": "Naira Matosyan",
      "userId": "06300012502933898371"
     }
    },
    "outputId": "1b34feb8-d67b-4144-ce7b-fe50af93c98b"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 0/42\n",
      "Batch: 1/42\n",
      "Batch: 2/42\n",
      "Batch: 3/42\n",
      "Batch: 4/42\n",
      "Batch: 5/42\n",
      "Batch: 6/42\n",
      "Batch: 7/42\n",
      "Batch: 8/42\n",
      "Batch: 9/42\n",
      "Batch: 10/42\n",
      "Batch: 11/42\n",
      "Batch: 12/42\n",
      "Batch: 13/42\n",
      "Batch: 14/42\n",
      "Batch: 15/42\n",
      "Batch: 16/42\n",
      "Batch: 17/42\n",
      "Batch: 18/42\n",
      "Batch: 19/42\n",
      "Batch: 20/42\n",
      "Batch: 21/42\n",
      "Batch: 22/42\n",
      "Batch: 23/42\n",
      "Batch: 24/42\n",
      "Batch: 25/42\n",
      "Batch: 26/42\n",
      "Batch: 27/42\n",
      "Batch: 28/42\n",
      "Batch: 29/42\n",
      "Batch: 30/42\n",
      "Batch: 31/42\n",
      "Batch: 32/42\n",
      "Batch: 33/42\n",
      "Batch: 34/42\n",
      "Batch: 35/42\n",
      "Batch: 36/42\n",
      "Batch: 37/42\n",
      "Batch: 38/42\n",
      "Batch: 39/42\n",
      "Batch: 40/42\n",
      "Batch: 41/42\n"
     ]
    }
   ],
   "source": [
    "# Evaluate LSTM\n",
    "\n",
    "checkpoint = torch.load('drive/MyDrive/checkpoints/lstm/epoch_29.pth')\n",
    "loaded_model = InstrumentLSTM(num_classes)\n",
    "loaded_model.load_state_dict(checkpoint)\n",
    "loaded_model = loaded_model.to(device)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loaded_model.eval()\n",
    "y_true_lstm, y_pred_lstm = [], []\n",
    "with torch.no_grad():\n",
    "    for batch, (X, y) in enumerate(test_dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        X = X.transpose(1, 2)\n",
    "        output = loaded_model(X).to(device)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        y_true_lstm.extend(y)\n",
    "        y_pred_lstm.extend(predicted.cpu())\n",
    "        print(f\"Batch: {batch}/{len(test_dataloader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ef80a18",
   "metadata": {
    "id": "1ef80a18",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1707638093645,
     "user_tz": -240,
     "elapsed": 384,
     "user": {
      "displayName": "Naira Matosyan",
      "userId": "06300012502933898371"
     }
    }
   },
   "outputs": [],
   "source": [
    "def to_cpu(data):\n",
    "    data_cpu = []\n",
    "    for tensor in data:\n",
    "        data_cpu.append(int(tensor.cpu().numpy()))\n",
    "    return data_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6c7761a9",
   "metadata": {
    "id": "6c7761a9",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1707640169210,
     "user_tz": -240,
     "elapsed": 1321,
     "user": {
      "displayName": "Naira Matosyan",
      "userId": "06300012502933898371"
     }
    }
   },
   "outputs": [],
   "source": [
    "def compute_accuracy_measures(y_true, y_pred):\n",
    "  classes = ['cel', 'cla', 'flu', 'gac', 'gel', 'org', 'pia', 'sax', 'tru', 'vio', 'voi']\n",
    "  y_true_cpu = to_cpu(y_true)\n",
    "  y_pred_cpu = to_cpu(y_pred)\n",
    "  cm = confusion_matrix(y_true_cpu, y_pred_cpu)\n",
    "\n",
    "  df_cm = pd.DataFrame(cm, columns=classes, index=classes)\n",
    "\n",
    "  df_cm.index.name = 'Actual'\n",
    "  df_cm.columns.name = 'Predicted'\n",
    "  print('Confusion Matrix:')\n",
    "  print(df_cm)\n",
    "  # Compute the accuracy, precision, recall, and F1 score\n",
    "  accuracy = accuracy_score(y_true_cpu, y_pred_cpu)\n",
    "  precision = precision_score(y_true_cpu, y_pred_cpu, average='macro')\n",
    "  recall = recall_score(y_true_cpu, y_pred_cpu, average='macro')\n",
    "  f1 = f1_score(y_true_cpu, y_pred_cpu, average='macro')\n",
    "\n",
    "  print(f\"Accuracy: {accuracy}\")\n",
    "  print(f\"Precision: {precision}\")\n",
    "  print(f\"Recall: {recall}\")\n",
    "  print(f\"F1 score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "compute_accuracy_measures(y_true_cnn, y_pred_cnn)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1t9L442bErse",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1707640363535,
     "user_tz": -240,
     "elapsed": 1309,
     "user": {
      "displayName": "Naira Matosyan",
      "userId": "06300012502933898371"
     }
    },
    "outputId": "516be847-a13d-4056-f2d0-efe1b7511f5d"
   },
   "id": "1t9L442bErse",
   "execution_count": 71,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Confusion Matrix:\n",
      "Predicted  cel  cla  flu  gac  gel  org  pia  sax  tru  vio  voi\n",
      "Actual                                                          \n",
      "cel         76    0    0    0    0    0    2    0    0    0    0\n",
      "cla          0   99    0    0    0    0    0    0    0    2    0\n",
      "flu          0    0   85    0    0    0    0    0    0    5    0\n",
      "gac         10    0    0   20   23    0   12    1    0   61    0\n",
      "gel          0    0    0    0  152    0    0    0    0    0    0\n",
      "org          2    0    0    0    2  114    2    0    0   16    0\n",
      "pia          0    0    0    0    0    0  142    0    0    2    0\n",
      "sax          0    0    0    0    0    0    0  118    0    7    0\n",
      "tru          1    0    0    0    1    0    0    0  105    8    0\n",
      "vio          0    0    0    0    0    0    0    0    0  116    0\n",
      "voi          1    0    0    0    0    0    0    0    0    5  149\n",
      "Accuracy: 0.878267363704257\n",
      "Precision: 0.9192027606461166\n",
      "Recall: 0.8817419963305728\n",
      "F1 score: 0.8636655501520051\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "compute_accuracy_measures(y_true_lstm, y_pred_lstm)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DiMKEaqylN5J",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1707640296491,
     "user_tz": -240,
     "elapsed": 419,
     "user": {
      "displayName": "Naira Matosyan",
      "userId": "06300012502933898371"
     }
    },
    "outputId": "a23fca05-1e04-448c-84a6-886a8e941d7e"
   },
   "id": "DiMKEaqylN5J",
   "execution_count": 69,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Confusion Matrix:\n",
      "Predicted  cel  cla  flu  gac  gel  org  pia  sax  tru  vio  voi\n",
      "Actual                                                          \n",
      "cel         74    1    0    0    0    0    0    0    0    3    0\n",
      "cla          0   98    0    0    0    1    1    1    0    0    0\n",
      "flu          0    0   90    0    0    0    0    0    0    0    0\n",
      "gac          1    0    1  123    0    1    0    1    0    0    0\n",
      "gel          0    0    0    1  144    0    1    6    0    0    0\n",
      "org          0    0    0    0    1  132    2    0    0    0    1\n",
      "pia          0    0    1    0    0    1  140    2    0    0    0\n",
      "sax          0    0    0    0    2    1    0  121    0    0    1\n",
      "tru          0    1    0    0    0    0    0    0  114    0    0\n",
      "vio          0    0    1    0    0    0    0    0    1  114    0\n",
      "voi          0    0    0    0    0    0    0    0    0    0  155\n",
      "Accuracy: 0.9746079163554892\n",
      "Precision: 0.9750304519174382\n",
      "Recall: 0.9745237056830461\n",
      "F1 score: 0.9746272183640734\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75c321d2",
   "metadata": {
    "id": "75c321d2",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1707638401749,
     "user_tz": -240,
     "elapsed": 441,
     "user": {
      "displayName": "Naira Matosyan",
      "userId": "06300012502933898371"
     }
    }
   },
   "outputs": [],
   "source": [
    "def read_file(path):\n",
    "    #load the waveform y and sampling rate s\n",
    "    audio, sr = librosa.load(path)\n",
    "\n",
    "    # Get the duration of the audio\n",
    "    duration = librosa.get_duration(y=audio, sr=sr)\n",
    "\n",
    "    # Generate a random start time within the audio duration, ensuring it is at least 3 seconds from the end\n",
    "    start_time = random.uniform(0, duration - 3)\n",
    "\n",
    "    # Calculate the end time by adding 3 seconds to the start time\n",
    "    end_time = start_time + 3\n",
    "\n",
    "    # Extract the 3-second segment from the audio\n",
    "    random_3_seconds = audio[int(start_time * sr):int(end_time * sr)]\n",
    "\n",
    "    sp = librosa.feature.melspectrogram(y=random_3_seconds, sr=sr, n_mels=128,fmax=11025)\n",
    "    return torch.from_numpy(sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c6419bcc",
   "metadata": {
    "id": "c6419bcc",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1707639566046,
     "user_tz": -240,
     "elapsed": 3,
     "user": {
      "displayName": "Naira Matosyan",
      "userId": "06300012502933898371"
     }
    }
   },
   "outputs": [],
   "source": [
    "def predict(path):\n",
    "    classes = ['cello', 'clarinet', 'flute', 'acoustic guitar', 'electric guitar', 'organ', 'piano', 'saxophone', 'trumpet', 'violin', 'human singing voice']\n",
    "    sp_torch = read_file(path)\n",
    "    # CNN\n",
    "    checkpoint = torch.load('drive/MyDrive/checkpoints/cnn/epoch_29.pth')\n",
    "    loaded_model_cnn = InstrumentCNN(num_classes)\n",
    "    loaded_model_cnn.load_state_dict(checkpoint)\n",
    "    loaded_model_cnn = loaded_model_cnn.to(device)\n",
    "    loaded_model_cnn.eval()\n",
    "    sp_cnn = sp_torch.to(device).unsqueeze(0).unsqueeze(0)\n",
    "    output = loaded_model_cnn(sp_cnn).to(device)\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "    print(f\"The predicted instrument from CNN is: {classes[predicted]}\")\n",
    "\n",
    "    # LSTM\n",
    "    checkpoint = torch.load('drive/MyDrive/checkpoints/lstm/epoch_29.pth')\n",
    "    loaded_model_lstm = InstrumentLSTM(num_classes)\n",
    "    loaded_model_lstm.load_state_dict(checkpoint)\n",
    "    loaded_model_lstm = loaded_model_lstm.to(device)\n",
    "    loaded_model_lstm.eval()\n",
    "    sp_lstm = sp_torch.to(device).unsqueeze(0).transpose(1, 2)\n",
    "    output = loaded_model_lstm(sp_lstm).to(device)\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "    print(f\"The predicted instrument from LSTM is: {classes[predicted]}\")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "predict('drive/MyDrive/audio_test_data/[1] - 03 - Alexandre Lagoya - Canarios (Sanz)-1.wav')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2edILIXkLmn-",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1707639847052,
     "user_tz": -240,
     "elapsed": 1154,
     "user": {
      "displayName": "Naira Matosyan",
      "userId": "06300012502933898371"
     }
    },
    "outputId": "b8196e75-5ca2-4017-8f7f-b6cf9c726e91"
   },
   "id": "2edILIXkLmn-",
   "execution_count": 63,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The predicted instrument from CNN is: piano\n",
      "The predicted instrument from LSTM is: violin\n"
     ]
    }
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "a8926c2f3a114d14b668bbe75e90c39b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a2358816bb7a4cf6ac325ea2afc66f53",
       "IPY_MODEL_c319a55f2c86488fa527d0afec77abb3",
       "IPY_MODEL_48645e504a8e4d238809feca3f4eea46"
      ],
      "layout": "IPY_MODEL_27b278f7ba124188a95967c48687ae51"
     }
    },
    "a2358816bb7a4cf6ac325ea2afc66f53": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9af1f6bc7bef46c68da8f5faac96c89c",
      "placeholder": "​",
      "style": "IPY_MODEL_665621f698ca40e7b12add05a3695c88",
      "value": "100%"
     }
    },
    "c319a55f2c86488fa527d0afec77abb3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e73dc229b0c041ccb9c2a0c2a0cddd1c",
      "max": 30,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fdee0def9dc44d9d9b0e5ab2b133c1b4",
      "value": 30
     }
    },
    "48645e504a8e4d238809feca3f4eea46": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_efb35c962e6541608d2362f068b06c67",
      "placeholder": "​",
      "style": "IPY_MODEL_d4b3a2a5f7a14af2999b9c9e32aab348",
      "value": " 30/30 [1:51:54&lt;00:00, 147.52s/it]"
     }
    },
    "27b278f7ba124188a95967c48687ae51": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9af1f6bc7bef46c68da8f5faac96c89c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "665621f698ca40e7b12add05a3695c88": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e73dc229b0c041ccb9c2a0c2a0cddd1c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fdee0def9dc44d9d9b0e5ab2b133c1b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "efb35c962e6541608d2362f068b06c67": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d4b3a2a5f7a14af2999b9c9e32aab348": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
